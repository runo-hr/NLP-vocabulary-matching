{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6ee0cb-319c-4e09-aa5d-c513549623f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from thefuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e73076-c88c-4cb5-a631-bd1c2993fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_matches(df1, df2):\n",
    "    # list of items to iterate over. \n",
    "    # Will be modified in every iteration where a match is found\n",
    "    src1 = df1.name.to_list()\n",
    "    src2 = df2.name.to_list()\n",
    "    \n",
    "    # name(key), id(value) dictionaries\n",
    "    src1_dict = df1.name.to_dict()\n",
    "    src2_dict = dict([(value, key) for key, value in src1_dict.items()])\n",
    "\n",
    "    src2_dict = df2.name.to_dict()\n",
    "    src2_dict = dict([(value, key) for key, value in src2_dict.items()])\n",
    "    \n",
    "    # lists to create pandas dataframes\n",
    "    matched_ids = []\n",
    "    matched_names_ids = []\n",
    "    def get_match(src1, src2):\n",
    "        for item in src1:\n",
    "            best_match = process.extractOne(item, src2, scorer=fuzz.partial_token_sort_ratio)\n",
    "            confidence = best_match[1]\n",
    "            if confidence == 100:\n",
    "                src1_item_id = src1_dict[item]\n",
    "\n",
    "                src2_item = best_match[0]\n",
    "                src2_item_id = src2_dict[src2_item]\n",
    "\n",
    "                matched_ids.append(dict(source_1=src1_item_id, source_2=src2_item_id))\n",
    "                df_ids = pd.DataFrame(matched_ids)\n",
    "                df_ids.to_csv('matched_ids.csv')\n",
    "\n",
    "                matched_names_ids.append(dict(id1=src1_item_id, source_1=item, id2=src2_item_id,source_2=src2_item))\n",
    "                df_names_ids = pd.DataFrame(matched_names_ids)\n",
    "                df_names_ids.to_csv('matched_names_ids.csv')\n",
    "\n",
    "                src1.remove(item)\n",
    "                src2.remove(src2_item)\n",
    "\n",
    "                print(df_names_ids)\n",
    "                return get_match(src1, src2)\n",
    "            else:\n",
    "                continue\n",
    "    return matched_ids, matched_names_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c94eb6-a72c-4396-a36e-a50a0022217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_matched = pd.read_csv('matched_data.csv')\n",
    "df_s1 = pd.read_csv('source_1.csv')\n",
    "df_s2 = pd.read_csv('source_2.csv')\n",
    "\n",
    "closest_matches(df_s1, df_s2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (gro)",
   "language": "python",
   "name": "gro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
